# ADR-0015: Separate Slack Apps for MCP and ACP Protocols

**Status**: Accepted  
**Date**: 2026-03-01  
**Phase**: 005-intercom-acp-server, Phase 9  

## Context

The `agent-intercom` server supports two protocol modes: MCP (Model Context
Protocol via rmcp) and ACP (Agent Communication Protocol via NDJSON
stdin/stdout streams). Both modes use Slack as the operator interface for
approvals, prompt forwarding, status updates, and session management.

During Phase 9 implementation, the question arose: when an operator runs both
an MCP bridge and an ACP bridge against the same workspace, how should Slack
messages be routed to avoid thread collisions and interaction confusion?

Three options were evaluated:

| Option | Description | Feasibility |
|--------|-------------|-------------|
| A | Two server processes, two Slack apps | Works today, no code changes |
| B | Two server processes, one Slack app | Broken â€” Socket Mode allows one WebSocket per app token |
| C | One process, dual-mode with per-session driver routing | Significant refactor, couples failure modes |

### Current Architecture Constraints

1. **`AppState.driver`** is a single `Arc<dyn AgentDriver>` chosen at startup
   based on `--mode mcp` or `--mode acp`. Slack event handlers call
   `state.driver.resolve_clearance()` etc. with no per-session routing.

2. **Socket Mode** establishes exactly one WebSocket per app token. Two
   processes sharing the same token would steal each other's connection.

3. **`session.protocol_mode`** (MCP or ACP) is stored in the database but is
   not used for driver dispatch â€” it is metadata only.

## Decision

Use **separate Slack apps** for MCP and ACP server instances (Option A).

Each `agent-intercom` process runs with its own Slack app credentials
(bot token + app token) stored in the OS keychain under distinct service
names or environment variable prefixes.

Both apps may post to the **same Slack channel** â€” Slack threads are
per-bot, so there is no collision. Alternatively, operators may configure
different channels per app for complete visual separation.

### Credential Resolution (Mode-Prefixed)

`load_credentials(mode)` resolves each credential using a four-step
fallback chain. The first non-empty value wins:

| Priority | Source | ACP Example | MCP Example |
|----------|--------|-------------|-------------|
| 1 | Keyring `agent-intercom-{mode}` | `agent-intercom-acp` / `slack_bot_token` | `agent-intercom` / `slack_bot_token` |
| 2 | Env var `{VAR}_{MODE}` | `SLACK_BOT_TOKEN_ACP` | `SLACK_BOT_TOKEN` |
| 3 | Keyring `agent-intercom` (shared) | `agent-intercom` / `slack_bot_token` | *(same as #1)* |
| 4 | Env var `{VAR}` (shared) | `SLACK_BOT_TOKEN` | *(same as #2)* |

MCP is the default protocol, so its mode suffix is empty â€” steps 1â€“2
are identical to 3â€“4, preserving full backwards compatibility.

ACP-mode env vars: `SLACK_APP_TOKEN_ACP`, `SLACK_BOT_TOKEN_ACP`,
`SLACK_TEAM_ID_ACP`, `SLACK_MEMBER_IDS_ACP`.

## Consequences

### Positive

- **Backwards compatible**: existing deployments with un-prefixed env vars
  continue to work unchanged for MCP mode.
- **Visual clarity**: different bot names and avatars make MCP vs ACP messages
  immediately distinguishable in Slack.
- **Independent rate limits**: ACP sessions (potentially many concurrent child
  processes) cannot exhaust the MCP app's Slack API budget.
- **Failure isolation**: a crash or hang in one server does not affect the
  other's Slack connectivity.
- **Thread isolation for free**: each bot's messages naturally form separate
  threads even in the same channel.

### Negative

- **Two Slack apps to manage**: operators must install and configure two apps
  in their Slack workspace (two OAuth flows, two sets of scopes).
- **Two credential entries**: two keychain entries (or two sets of environment
  variables) for Slack tokens.
- **Two config files**: each process needs its own `config.toml` (or the same
  file with a `--profile` flag, which does not exist yet).

### Risks

- If a future requirement demands a unified Slack experience (single bot,
  single thread per workspace), this decision would need to be revisited
  with Option C (dual-mode server). That refactor is estimated at 2â€“3 phases
  of work: dispatcher driver, per-session routing in all Slack handlers, and
  concurrent transport management.

## IPC Pipe Isolation

When two server instances run on the same machine, they must bind different
named pipes to avoid collisions. The server auto-suffixes the `ipc_name`
config field when running in ACP mode and the name is still the default:

| Mode | Default `ipc_name` | Named Pipe (Windows) |
|------|--------------------|----------------------|
| MCP  | `agent-intercom`     | `\\.\pipe\agent-intercom` |
| ACP  | `agent-intercom-acp` | `\\.\pipe\agent-intercom-acp` |

The `agent-intercom-ctl` companion CLI has a `--mode` flag that performs
the same derivation:

```powershell
# Talk to the MCP server (default)
agent-intercom-ctl list

# Talk to the ACP server
agent-intercom-ctl --mode acp list

# Explicit override (takes precedence over --mode)
agent-intercom-ctl --ipc-name custom-name list
```

## Deployment Pattern

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Slack Workspace                                â”‚
â”‚                                                 â”‚
â”‚  #intercom-ops channel                          â”‚
â”‚    â”œâ”€â”€ ğŸŸ¢ Intercom MCP  (thread: session abcâ€¦) â”‚
â”‚    â”œâ”€â”€ ğŸŸ¢ Intercom MCP  (thread: session defâ€¦) â”‚
â”‚    â”œâ”€â”€ ğŸ”µ Intercom ACP  (thread: session 123â€¦) â”‚
â”‚    â””â”€â”€ ğŸ”µ Intercom ACP  (thread: session 456â€¦) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                          â–²
        â”‚ Socket Mode              â”‚ Socket Mode
        â”‚                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ agent-intercom â”‚        â”‚ agent-intercom â”‚
â”‚ --mode mcp     â”‚        â”‚ --mode acp     â”‚
â”‚ Bot: MCP App   â”‚        â”‚ Bot: ACP App   â”‚
â”‚ SLACK_BOT_TOKENâ”‚        â”‚ SLACK_BOT_     â”‚
â”‚ (shared name)  â”‚        â”‚ TOKEN_ACP      â”‚
â”‚ Port: 3000     â”‚        â”‚ Port: 3001     â”‚
â”‚ DB: intercom   â”‚        â”‚ DB: intercom   â”‚
â”‚   -mcp.db      â”‚        â”‚   -acp.db      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Both servers may share the same workspace root directories and policy files
(`.agentrc/settings.json`). They use separate SQLite databases to avoid
write contention.

### Example: Running Both Servers

```powershell
# Terminal 1 â€” MCP server (uses default/shared env vars)
$env:SLACK_BOT_TOKEN  = "xoxb-mcp-bot-token"
$env:SLACK_APP_TOKEN  = "xapp-mcp-app-token"
$env:SLACK_MEMBER_IDS = "U0123456789"
agent-intercom --mode mcp --config config-mcp.toml

# Terminal 2 â€” ACP server (ACP-suffixed env vars take priority)
$env:SLACK_BOT_TOKEN_ACP  = "xoxb-acp-bot-token"
$env:SLACK_APP_TOKEN_ACP  = "xapp-acp-app-token"
$env:SLACK_MEMBER_IDS_ACP = "U0123456789"
agent-intercom --mode acp --config config-acp.toml
```
